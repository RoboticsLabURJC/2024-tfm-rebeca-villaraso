---
title: "Week 14 - Changing everything"
image: ../assets/images/logo.png
categories:
  - Weekly Log
tags:
  - GitHub Pages
  - ROS2
  - Gazebo
  - PID Controllers
  - Autonomous Driving
  - Neural Networks
  - Machine Learning
---

# Progress This Week

## Objective

This time, instead of focusing on creating new pilots, we are gonna focus on how we create them and what we know about them.

It is worth saying that we improved slightly the expert pilot and generated a new rosbag.

## Data analysis

First I refined the graphs generated from the rosbags recorded. The actual dataset has this distribution

<figure class="align-center" style="width:70%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Week-14/Datos_E2.png" alt="">
  <figcaption>My datasets</figcaption>
</figure>

Looking at it I realized the amount of data of curves to each side was different, so I balanced the data:

<figure class="align-center" style="width:70%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Week-14/Balanced_data_e2.png" alt="">
  <figcaption>My datasets</figcaption>
</figure>

And with this I trained a pilot to test it, I won't bother with videos graphs because the pilots have been discarded for now.

## Training

One of the many problems I have been having was that the trainer only supported small datasets, this was because I was oppening the rosbag and all the data, and then spliting it a training. So I had thousands of images opend at the same time, which coused a crash. I was also balancing the data and augmenting it before the training (not storing it just processing the data from the rosbag) which is a bad practise and also makes it harder for the PC.

The summury: I was doing the training all wrong and I had to re do it.

Most of the code used is again not mine but from https://github.com/JdeRobot/DeepLearningStudio with some alterations to fit my needs.

### Storing the data

This was not too hard given that I had already worked a lot with reading the data from the rosbag, all I needed was to store the velocity comands in a csv, which was not hard to create, and save the images. In order to use correctly the neural net I cropped the images, cuting the top half wich had no relevant information.

### Training the PilotNet

First I had to generate the Dataset by loading all the velocity commands and images and aplying preprocesing and data augmentation if needed. Ausefull thing in this concrete case is to flip the images around its vertical axis and negate the angular velocity. In other cases this might not work, but in this simple circuits were the only relevant information is the red line in the center it actually works.

After that not much diference exists in selecting the loss criteria, optimizer, spliting the data into training and validation...

And so I started my first pilot. It went backward, I restarted and forward... It was inconsistent, but always really small speeds, amde no sense... Until I realized I was giving it the image withouth cropping, so I cropped it and tried again. Same result.

I checked my csv, all correct; the data I was loading, all correct; the dataset... The way I was fliping the data was changing things I did not want it to change, so I commented it (I intend to go back to it when the rest works) and went back to it... No change.

I kept traicing and checking things and I could find nothing, I can't say the amount of time spent without knowing why my net not only did not advance, but it was inconsistent from start, the values seamed compleatly random... Well, it results they were, I was not loading the actual saved net.

With that I was able to train a pilot that went forward. It steel doesn't work well, and it is not turning at the moment, but at least it doesn't seam random.

---