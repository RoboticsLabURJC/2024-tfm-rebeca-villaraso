{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d906ad-d6a8-458a-bb03-30e1c436d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained resnet, 18\n",
      "00\n",
      "num_val_batches: 299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bfzjs\\Anaconda3\\envs\\Pytorch39\\lib\\site-packages\\torch\\nn\\functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "num_val_batches: 550\n"
     ]
    }
   ],
   "source": [
    "# camera-ready\n",
    "\n",
    "import sys,os\n",
    "current_path=os.getcwd()\n",
    "\n",
    "#sys.path.append(\"/root/deeplabv3\")\n",
    "sys.path.append(current_path)\n",
    "from datasets import DatasetSeq # (this needs to be imported before torch, because cv2 needs to be imported before torch for some reason)\n",
    "\n",
    "#sys.path.append(\"/root/deeplabv3/model\")\n",
    "sys.path.append(current_path + \"/model\")\n",
    "from deeplabv3 import DeepLabV3\n",
    "\n",
    "#sys.path.append(\"/root/deeplabv3/utils\")\n",
    "sys.path.append(current_path+\"/utils\")\n",
    "from utils import label_img_to_color\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "batch_size = 2\n",
    "current_path=os.getcwd()\n",
    "#network = DeepLabV3(\"eval_seq\", project_dir=\"/root/deeplabv3\").cuda()\n",
    "network = DeepLabV3(\"eval_seq\", project_dir=current_path).cuda()\n",
    "\n",
    "#network.load_state_dict(torch.load(\"/root/deeplabv3/pretrained_models/model_13_2_2_2_epoch_580.pth\"))\n",
    "network.load_state_dict(torch.load(current_path+\"/pretrained_models/model_13_2_2_2_epoch_580.pth\"))\n",
    "\n",
    "for sequence in [\"00\", \"01\", \"02\"]:\n",
    "    print (sequence)\n",
    "\n",
    "    #val_dataset = DatasetSeq(cityscapes_data_path=\"/root/deeplabv3/data/cityscapes\",\n",
    "    #                         cityscapes_meta_path=\"/root/deeplabv3/data/cityscapes/meta\",\n",
    "    #                         sequence=sequence)\n",
    "    val_dataset = DatasetSeq(cityscapes_data_path=current_path+\"/data/cityscapes\",\n",
    "                             cityscapes_meta_path=current_path+\"/data/cityscapes/meta\",\n",
    "                             sequence=sequence)\n",
    "    num_val_batches = int(len(val_dataset)/batch_size)\n",
    "    print (\"num_val_batches:\", num_val_batches)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                             batch_size=batch_size, shuffle=False,\n",
    "                                             num_workers=1)\n",
    "\n",
    "    network.eval() # (set in evaluation mode, this affects BatchNorm and dropout)\n",
    "    unsorted_img_ids = []\n",
    "    for step, (imgs, img_ids) in enumerate(val_loader):\n",
    "        with torch.no_grad(): # (corresponds to setting volatile=True in all variables, this is done during inference to reduce memory consumption)\n",
    "            imgs = Variable(imgs).cuda() # (shape: (batch_size, 3, img_h, img_w))\n",
    "\n",
    "            outputs = network(imgs) # (shape: (batch_size, num_classes, img_h, img_w))\n",
    "\n",
    "            ####################################################################\n",
    "            # save data for visualization:\n",
    "            ####################################################################\n",
    "            outputs = outputs.data.cpu().numpy() # (shape: (batch_size, num_classes, img_h, img_w))\n",
    "            pred_label_imgs = np.argmax(outputs, axis=1) # (shape: (batch_size, img_h, img_w))\n",
    "            pred_label_imgs = pred_label_imgs.astype(np.uint8)\n",
    "\n",
    "            for i in range(pred_label_imgs.shape[0]):\n",
    "                pred_label_img = pred_label_imgs[i] # (shape: (img_h, img_w))\n",
    "                img_id = img_ids[i]\n",
    "                img = imgs[i] # (shape: (3, img_h, img_w))\n",
    "\n",
    "                img = img.data.cpu().numpy()\n",
    "                img = np.transpose(img, (1, 2, 0)) # (shape: (img_h, img_w, 3))\n",
    "                img = img*np.array([0.229, 0.224, 0.225])\n",
    "                img = img + np.array([0.485, 0.456, 0.406])\n",
    "                img = img*255.0\n",
    "                img = img.astype(np.uint8)\n",
    "\n",
    "                pred_label_img_color = label_img_to_color(pred_label_img)\n",
    "                overlayed_img = 0.35*img + 0.65*pred_label_img_color\n",
    "                overlayed_img = overlayed_img.astype(np.uint8)\n",
    "\n",
    "                img_h = overlayed_img.shape[0]\n",
    "                img_w = overlayed_img.shape[1]\n",
    "\n",
    "                cv2.imwrite(network.model_dir + \"/\" + img_id + \".png\", img)\n",
    "                cv2.imwrite(network.model_dir + \"/\" + img_id + \"_pred.png\", pred_label_img_color)\n",
    "                cv2.imwrite(network.model_dir + \"/\" + img_id + \"_overlayed.png\", overlayed_img)\n",
    "\n",
    "                unsorted_img_ids.append(img_id)\n",
    "\n",
    "    ############################################################################\n",
    "    # create visualization video:\n",
    "    ############################################################################\n",
    "    out = cv2.VideoWriter(\"%s/stuttgart_%s_combined.avi\" % (network.model_dir, sequence), cv2.VideoWriter_fourcc(*\"MJPG\"), 20, (2*img_w, 2*img_h))\n",
    "    sorted_img_ids = sorted(unsorted_img_ids)\n",
    "    for img_id in sorted_img_ids:\n",
    "        img = cv2.imread(network.model_dir + \"/\" + img_id + \".png\", -1)\n",
    "        pred_img = cv2.imread(network.model_dir + \"/\" + img_id + \"_pred.png\", -1)\n",
    "        overlayed_img = cv2.imread(network.model_dir + \"/\" + img_id + \"_overlayed.png\", -1)\n",
    "\n",
    "        combined_img = np.zeros((2*img_h, 2*img_w, 3), dtype=np.uint8)\n",
    "\n",
    "        combined_img[0:img_h, 0:img_w] = img\n",
    "        combined_img[0:img_h, img_w:(2*img_w)] = pred_img\n",
    "        combined_img[img_h:(2*img_h), (int(img_w/2)):(img_w + int(img_w/2))] = overlayed_img\n",
    "\n",
    "        out.write(combined_img)\n",
    "\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee0b75-a946-4ab3-a43e-2adf8331b296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
