{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732c7ee1-eeaf-4eca-a8cc-80cec4430b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained resnet, 18\n",
      "num_val_batches: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bfzjs\\Anaconda3\\envs\\Pytorch39\\lib\\site-packages\\torch\\nn\\functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.540574\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "current_path=os.getcwd()\n",
    "#sys.path.append(\"/root/deeplabv3\")\n",
    "sys.path.append(current_path)\n",
    "from datasets import DatasetVal # (this needs to be imported before torch, because cv2 needs to be imported before torch for some reason)\n",
    "\n",
    "#sys.path.append(\"/root/deeplabv3/model\")\n",
    "sys.path.append(current_path+\"/model\")\n",
    "from deeplabv3 import DeepLabV3\n",
    "\n",
    "#sys.path.append(\"/root/deeplabv3/utils\")\n",
    "sys.path.append(current_path+\"/utils\")\n",
    "from utils import label_img_to_color\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "trainId_to_id = {\n",
    "    0: 7,\n",
    "    1: 8,\n",
    "    2: 11,\n",
    "    3: 12,\n",
    "    4: 13,\n",
    "    5: 17,\n",
    "    6: 19,\n",
    "    7: 20,\n",
    "    8: 21,\n",
    "    9: 22,\n",
    "    10: 23,\n",
    "    11: 24,\n",
    "    12: 25,\n",
    "    13: 26,\n",
    "    14: 27,\n",
    "    15: 28,\n",
    "    16: 31,\n",
    "    17: 32,\n",
    "    18: 33,\n",
    "    19: 0\n",
    "}\n",
    "trainId_to_id_map_func = np.vectorize(trainId_to_id.get)\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "#network = DeepLabV3(\"eval_val_for_metrics\", project_dir=\"/root/deeplabv3\").cuda()\n",
    "#network.load_state_dict(torch.load(\"/root/deeplabv3/pretrained_models/model_13_2_2_2_epoch_580.pth\"))\n",
    "network = DeepLabV3(\"eval_val_for_metrics\", project_dir=current_path).cuda()\n",
    "network.load_state_dict(torch.load(current_path+\"/pretrained_models/model_13_2_2_2_epoch_580.pth\"))\n",
    "\n",
    "#val_dataset = DatasetVal(cityscapes_data_path=\"/root/deeplabv3/data/cityscapes\",\n",
    "#                         cityscapes_meta_path=\"/root/deeplabv3/data/cityscapes/meta\")\n",
    "val_dataset = DatasetVal(cityscapes_data_path=current_path+\"/data/cityscapes\",\n",
    "                         cityscapes_meta_path=current_path+\"/data/cityscapes/meta\")\n",
    "\n",
    "num_val_batches = int(len(val_dataset)/batch_size)\n",
    "print (\"num_val_batches:\", num_val_batches)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                         batch_size=batch_size, shuffle=False,\n",
    "                                         num_workers=1)\n",
    "\n",
    "#with open(\"/root/deeplabv3/data/cityscapes/meta/class_weights.pkl\", \"rb\") as file: # (needed for python3)\n",
    "with open(current_path+\"/data/cityscapes/meta/class_weights.pkl\", \"rb\") as file: # (needed for python3)\n",
    "    class_weights = np.array(pickle.load(file))\n",
    "class_weights = torch.from_numpy(class_weights)\n",
    "class_weights = Variable(class_weights.type(torch.FloatTensor)).cuda()\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "network.eval() # (set in evaluation mode, this affects BatchNorm and dropout)\n",
    "batch_losses = []\n",
    "for step, (imgs, label_imgs, img_ids) in enumerate(val_loader):\n",
    "    with torch.no_grad(): # (corresponds to setting volatile=True in all variables, this is done during inference to reduce memory consumption)\n",
    "        imgs = Variable(imgs).cuda() # (shape: (batch_size, 3, img_h, img_w))\n",
    "        label_imgs = Variable(label_imgs.type(torch.LongTensor)).cuda() # (shape: (batch_size, img_h, img_w))\n",
    "\n",
    "        outputs = network(imgs) # (shape: (batch_size, num_classes, img_h, img_w))\n",
    "\n",
    "        # compute the loss:\n",
    "        loss = loss_fn(outputs, label_imgs)\n",
    "        loss_value = loss.data.cpu().numpy()\n",
    "        batch_losses.append(loss_value)\n",
    "\n",
    "        ########################################################################\n",
    "        # save data for visualization:\n",
    "        ########################################################################\n",
    "        outputs = F.upsample(outputs, size=(1024, 2048), mode=\"bilinear\") # (shape: (batch_size, num_classes, 1024, 2048))\n",
    "\n",
    "        outputs = outputs.data.cpu().numpy() # (shape: (batch_size, num_classes, 1024, 2048))\n",
    "        pred_label_imgs = np.argmax(outputs, axis=1) # (shape: (batch_size, 1024, 2048))\n",
    "        pred_label_imgs = pred_label_imgs.astype(np.uint8)\n",
    "\n",
    "        for i in range(pred_label_imgs.shape[0]):\n",
    "            pred_label_img = pred_label_imgs[i] # (shape: (1024, 2048))\n",
    "            img_id = img_ids[i]\n",
    "\n",
    "            # convert pred_label_img from trainId to id pixel values:\n",
    "            pred_label_img = trainId_to_id_map_func(pred_label_img) # (shape: (1024, 2048))\n",
    "            pred_label_img = pred_label_img.astype(np.uint8)\n",
    "\n",
    "            cv2.imwrite(network.model_dir + \"/\" + img_id + \"_pred_label_img.png\", pred_label_img)\n",
    "\n",
    "val_loss = np.mean(batch_losses)\n",
    "print (\"val loss: %g\" % val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672f2a9-bb00-43c4-ad2e-6856ebde8982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
