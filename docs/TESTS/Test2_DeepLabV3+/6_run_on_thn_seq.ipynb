{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfb254a-b443-43fc-8b1d-54350cef8088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained resnet, 18\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'C:\\\\Users\\\\bfzjs\\\\Desktop\\\\TFM\\\\TESTS\\\\T2_Cityscapes\\\\deeplabv3/data/thn/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m network\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(current_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/pretrained_models/model_13_2_2_2_epoch_580.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#val_dataset = DatasetThnSeq(thn_data_path=\"/root/deeplabv3/data/thn\")\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetThnSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthn_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data/thn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m num_val_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_dataset)\u001b[38;5;241m/\u001b[39mbatch_size)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_val_batches:\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_val_batches)\n",
      "File \u001b[1;32m~\\Desktop\\TFM\\TESTS\\T2_Cityscapes\\deeplabv3\\datasets.py:272\u001b[0m, in \u001b[0;36mDatasetThnSeq.__init__\u001b[1;34m(self, thn_data_path)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir \u001b[38;5;241m=\u001b[39m thn_data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexamples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 272\u001b[0m file_names \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m file_names:\n\u001b[0;32m    274\u001b[0m     img_id \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'C:\\\\Users\\\\bfzjs\\\\Desktop\\\\TFM\\\\TESTS\\\\T2_Cityscapes\\\\deeplabv3/data/thn/'"
     ]
    }
   ],
   "source": [
    "# camera-ready\n",
    "\n",
    "import sys,os\n",
    "\n",
    "current_path=os.getcwd()\n",
    "#sys.path.append(\"/root/deeplabv3\")\n",
    "sys.path.append(current_path)\n",
    "\n",
    "from datasets import DatasetThnSeq # (this needs to be imported before torch, because cv2 needs to be imported before torch for some reason)\n",
    "\n",
    "#sys.path.append(\"/root/deeplabv3/model\")\n",
    "sys.path.append(current_path+\"/model\")\n",
    "from deeplabv3 import DeepLabV3\n",
    "\n",
    "#sys.path.append(\"/root/deeplabv3/utils\")\n",
    "sys.path.append(current_path+\"/utils\")\n",
    "from utils import label_img_to_color\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "#network = DeepLabV3(\"eval_seq_thn\", project_dir=\"/root/deeplabv3\").cuda()\n",
    "network = DeepLabV3(\"eval_seq_thn\", project_dir=current_path).cuda()\n",
    "#network.load_state_dict(torch.load(\"/root/deeplabv3/pretrained_models/model_13_2_2_2_epoch_580.pth\"))\n",
    "network.load_state_dict(torch.load(current_path+\"/pretrained_models/model_13_2_2_2_epoch_580.pth\"))\n",
    "\n",
    "#val_dataset = DatasetThnSeq(thn_data_path=\"/root/deeplabv3/data/thn\")\n",
    "val_dataset = DatasetThnSeq(thn_data_path=current_path+\"/data/thn\")\n",
    "\n",
    "num_val_batches = int(len(val_dataset)/batch_size)\n",
    "print (\"num_val_batches:\", num_val_batches)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                         batch_size=batch_size, shuffle=False,\n",
    "                                         num_workers=1)\n",
    "\n",
    "network.eval() # (set in evaluation mode, this affects BatchNorm and dropout)\n",
    "unsorted_img_ids = []\n",
    "for step, (imgs, img_ids) in enumerate(val_loader):\n",
    "    with torch.no_grad(): # (corresponds to setting volatile=True in all variables, this is done during inference to reduce memory consumption)\n",
    "        imgs = Variable(imgs).cuda() # (shape: (batch_size, 3, img_h, img_w))\n",
    "\n",
    "        outputs = network(imgs) # (shape: (batch_size, num_classes, img_h, img_w))\n",
    "\n",
    "        ########################################################################\n",
    "        # save data for visualization:\n",
    "        ########################################################################\n",
    "        outputs = outputs.data.cpu().numpy() # (shape: (batch_size, num_classes, img_h, img_w))\n",
    "        pred_label_imgs = np.argmax(outputs, axis=1) # (shape: (batch_size, img_h, img_w))\n",
    "        pred_label_imgs = pred_label_imgs.astype(np.uint8)\n",
    "\n",
    "        for i in range(pred_label_imgs.shape[0]):\n",
    "            pred_label_img = pred_label_imgs[i] # (shape: (img_h, img_w))\n",
    "            img_id = img_ids[i]\n",
    "            img = imgs[i] # (shape: (3, img_h, img_w))\n",
    "\n",
    "            img = img.data.cpu().numpy()\n",
    "            img = np.transpose(img, (1, 2, 0)) # (shape: (img_h, img_w, 3))\n",
    "            img = img*np.array([0.229, 0.224, 0.225])\n",
    "            img = img + np.array([0.485, 0.456, 0.406])\n",
    "            img = img*255.0\n",
    "            img = img.astype(np.uint8)\n",
    "\n",
    "            pred_label_img_color = label_img_to_color(pred_label_img)\n",
    "            overlayed_img = 0.35*img + 0.65*pred_label_img_color\n",
    "            overlayed_img = overlayed_img.astype(np.uint8)\n",
    "\n",
    "            img_h = overlayed_img.shape[0]\n",
    "            img_w = overlayed_img.shape[1]\n",
    "\n",
    "            # TODO! do this using network.model_dir instead\n",
    "            cv2.imwrite(network.model_dir + \"/\" + img_id + \".png\", img)\n",
    "            cv2.imwrite(network.model_dir + \"/\" + img_id + \"_pred.png\", pred_label_img_color)\n",
    "            cv2.imwrite(network.model_dir + \"/\" + img_id + \"_overlayed.png\", overlayed_img)\n",
    "\n",
    "            unsorted_img_ids.append(img_id)\n",
    "\n",
    "################################################################################\n",
    "# create visualization video:\n",
    "################################################################################\n",
    "out = cv2.VideoWriter(\"%s/thn_combined.avi\" % network.model_dir, cv2.VideoWriter_fourcc(*\"MJPG\"), 12, (2*img_w, 2*img_h))\n",
    "sorted_img_ids = sorted(unsorted_img_ids)\n",
    "for img_id in sorted_img_ids:\n",
    "    img = cv2.imread(network.model_dir + \"/\" + img_id + \".png\", -1)\n",
    "    pred_img = cv2.imread(network.model_dir + \"/\" + img_id + \"_pred.png\", -1)\n",
    "    overlayed_img = cv2.imread(network.model_dir + \"/\" + img_id + \"_overlayed.png\", -1)\n",
    "\n",
    "    combined_img = np.zeros((2*img_h, 2*img_w, 3), dtype=np.uint8)\n",
    "\n",
    "    combined_img[0:img_h, 0:img_w] = img\n",
    "    combined_img[0:img_h, img_w:(2*img_w)] = pred_img\n",
    "    combined_img[img_h:(2*img_h), (int(img_w/2)):(img_w + int(img_w/2))] = overlayed_img\n",
    "\n",
    "    out.write(combined_img)\n",
    "\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88800e43-6d86-4217-a57a-e818accf2fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
